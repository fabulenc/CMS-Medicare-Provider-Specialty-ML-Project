{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import xgboost\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "\n",
    "\n",
    "X = pd.read_csv('X_3specialties_equalWeight_subsample.zip',compression='zip', index_col=False)\n",
    "y = pd.read_csv('y_3specialties_equalWeight_subsample.zip',compression='zip')\n",
    "groups = pd.read_csv('groups_3specialties_equalWeight_subsample.zip',compression='zip')\n",
    "\n",
    "X = X.iloc[:,1:]\n",
    "y = y.iloc[:,1:]\n",
    "groups = groups.iloc[:,1:]\n",
    "\n",
    "y_columns = y.columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = y.values.ravel()\n",
    "y = le.fit_transform(y)\n",
    "y = pd.DataFrame(y)\n",
    "y.columns = y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672.6400000000001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)*0.8*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_ftrs = ['Prscrbr_City',\n",
    "                    'Prscrbr_State_Abrvtn',\n",
    "                    'Brnd_Name',\n",
    "                    'Gnrc_Name']\n",
    "\n",
    "std_ftrs = ['Tot_Clms', \n",
    "            'Tot_30day_Fills', \n",
    "            'Tot_Day_Suply', \n",
    "            'Tot_Drug_Cst', \n",
    "            'Tot_Benes', \n",
    "            'GE65_Tot_Clms',\n",
    "            'GE65_Tot_30day_Fills',\n",
    "            'GE65_Tot_Drug_Cst',\n",
    "            'GE65_Tot_Day_Suply',\n",
    "            'GE65_Tot_Benes']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), categorical_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prscrbr_City</th>\n",
       "      <th>Prscrbr_State_Abrvtn</th>\n",
       "      <th>Brnd_Name</th>\n",
       "      <th>Gnrc_Name</th>\n",
       "      <th>Tot_Clms</th>\n",
       "      <th>Tot_30day_Fills</th>\n",
       "      <th>Tot_Day_Suply</th>\n",
       "      <th>Tot_Drug_Cst</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>GE65_Tot_Clms</th>\n",
       "      <th>GE65_Tot_30day_Fills</th>\n",
       "      <th>GE65_Tot_Drug_Cst</th>\n",
       "      <th>GE65_Tot_Day_Suply</th>\n",
       "      <th>GE65_Tot_Benes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4202</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4204 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prscrbr_City  Prscrbr_State_Abrvtn  Brnd_Name  Gnrc_Name  Tot_Clms  \\\n",
       "0            False                 False      False      False     False   \n",
       "1            False                 False      False      False     False   \n",
       "2            False                 False      False      False     False   \n",
       "3            False                 False      False      False     False   \n",
       "4            False                 False      False      False     False   \n",
       "...            ...                   ...        ...        ...       ...   \n",
       "4199         False                 False      False      False     False   \n",
       "4200         False                 False      False      False     False   \n",
       "4201         False                 False      False      False     False   \n",
       "4202         False                 False      False      False     False   \n",
       "4203         False                 False      False      False     False   \n",
       "\n",
       "      Tot_30day_Fills  Tot_Day_Suply  Tot_Drug_Cst  Tot_Benes  GE65_Tot_Clms  \\\n",
       "0               False          False         False       True           True   \n",
       "1               False          False         False       True          False   \n",
       "2               False          False         False       True          False   \n",
       "3               False          False         False      False          False   \n",
       "4               False          False         False       True          False   \n",
       "...               ...            ...           ...        ...            ...   \n",
       "4199            False          False         False       True          False   \n",
       "4200            False          False         False      False           True   \n",
       "4201            False          False         False       True          False   \n",
       "4202            False          False         False      False           True   \n",
       "4203            False          False         False       True           True   \n",
       "\n",
       "      GE65_Tot_30day_Fills  GE65_Tot_Drug_Cst  GE65_Tot_Day_Suply  \\\n",
       "0                     True               True                True   \n",
       "1                    False              False               False   \n",
       "2                    False              False               False   \n",
       "3                    False              False               False   \n",
       "4                    False              False               False   \n",
       "...                    ...                ...                 ...   \n",
       "4199                 False              False               False   \n",
       "4200                  True               True                True   \n",
       "4201                 False              False               False   \n",
       "4202                  True               True                True   \n",
       "4203                  True               True                True   \n",
       "\n",
       "      GE65_Tot_Benes  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3              False  \n",
       "4               True  \n",
       "...              ...  \n",
       "4199            True  \n",
       "4200            True  \n",
       "4201            True  \n",
       "4202            True  \n",
       "4203            True  \n",
       "\n",
       "[4204 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n",
      "[False False False False False False False False False False False False\n",
      " False False] 441\n",
      "[False False False False False False False False False False False False\n",
      " False  True] 587\n",
      "[False False False False False False False False False  True  True  True\n",
      "  True  True] 811\n",
      "[False False False False False False False False  True False False False\n",
      " False  True] 1303\n",
      "[False False False False False False False False  True  True  True  True\n",
      "  True  True] 1062\n"
     ]
    }
   ],
   "source": [
    "mask = X.isnull()\n",
    "\n",
    "unique_rows, counts = np.unique(mask, axis=0, return_counts=True)\n",
    "print(unique_rows.shape) # 5 patterns, we will train 6 models\n",
    "\n",
    "for i in range(len(counts)):\n",
    "    print(unique_rows[i],counts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model(X_train, Y_train, X_CV, y_CV, X_test, y_test, i, verbose=4):\n",
    "\n",
    "    # make into row vectors to avoid an obnoxious sklearn/xgb warning\n",
    "    Y_train = np.reshape(np.array(Y_train), (1, -1)).ravel()\n",
    "    y_CV = np.reshape(np.array(y_CV), (1, -1)).ravel()\n",
    "    y_test = np.reshape(np.array(y_test), (1, -1)).ravel()\n",
    "\n",
    "    XGB = xgboost.XGBClassifier(num_class=3,\n",
    "                                objective = \"multi:softprob\",\n",
    "                                eval_metric = 'mlogloss', \n",
    "                                random_state = i, \n",
    "                                use_label_encoder = False)\n",
    "    \n",
    "    # find the best parameter set\n",
    "    param_grid = {\"learning_rate\": [0.03],#0.01,\n",
    "                  \"n_estimators\": [10000],\n",
    "                  \"seed\": [i],\n",
    "                  \"reg_alpha\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                  #\"reg_lambda\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                  \"missing\": [np.nan], \n",
    "                  \"max_depth\": [3], #1,3,\n",
    "                  \"colsample_bytree\": [0.7],              \n",
    "                  \"subsample\": [0.7]} #, 0.9\n",
    "\n",
    "    pg = ParameterGrid(param_grid)\n",
    "\n",
    "    scores_f1 = np.zeros(len(pg))\n",
    "\n",
    "    #weights = compute_sample_weight(class_weight='balanced', y = Y_train)\n",
    "    \n",
    "    for i in range(len(pg)):\n",
    "        if verbose >= 5:\n",
    "            print(\"Param set \" + str(i + 1) + \" / \" + str(len(pg)))\n",
    "        params = pg[i]\n",
    "        XGB.set_params(**params)\n",
    "        eval_set = [(X_CV, y_CV)]\n",
    "        XGB.fit(X_train, Y_train,\n",
    "                early_stopping_rounds=50, eval_set=eval_set, verbose=False)\n",
    "                #sample_weight = weights)# with early stopping\n",
    "        y_CV_pred = XGB.predict(X_CV, iteration_range=(0, XGB.best_ntree_limit))\n",
    "        #scores[i] = accuracy_score(y_CV,y_CV_pred)\n",
    "        scores_f1[i] = f1_score(y_CV,y_CV_pred, average = 'macro')\n",
    "\n",
    "    best_params = np.array(pg)[scores_f1 == np.max(scores_f1)]\n",
    "    if verbose >= 4:\n",
    "        print('Test set max score and best parameters are:')\n",
    "        print(np.max(scores_f1))\n",
    "        print(best_params)\n",
    "        print()\n",
    "    # test the model on the test set with best parameter set\n",
    "    XGB.set_params(**best_params[0])\n",
    "    XGB.fit(X_train,Y_train,\n",
    "            early_stopping_rounds=50,eval_set=eval_set, verbose=False)\n",
    "    y_test_pred = XGB.predict(X_test, iteration_range=(0, XGB.best_ntree_limit))\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print ('The CV F1 is:',f1_score(y_CV,y_CV_pred, average = 'macro'))\n",
    "        print()\n",
    "    if verbose >= 2:\n",
    "        print ('The predictions are:')\n",
    "        print (y_test_pred)\n",
    "        print()\n",
    "    #if verbose >= 3:\n",
    "        #print(\"Feature importances:\")\n",
    "        #print(XGB.feature_importances_)\n",
    "    \n",
    "    return (f1_score(y_test,y_test_pred, average='macro'), y_test_pred, XGB.feature_importances_)\n",
    "    #return (y_test_pred, best_params, XGB.feature_importances_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Reduced-feature XGB model\n",
    "# all the inputs need to be pandas DataFrame\n",
    "def reduced_feature_xgb(X_train, Y_train, X_CV, y_CV, X_test, y_test, i):\n",
    "    \n",
    "    # find all unique patterns of missing value in test set\n",
    "    mask = X_test.isnull()\n",
    "    unique_rows = np.array(np.unique(mask, axis=0))\n",
    "    all_y_test_pred = pd.DataFrame()\n",
    "    \n",
    "    print('    There are', len(unique_rows), 'unique missing value patterns.')\n",
    "    print()\n",
    "    # divide test sets into subgroups according to the unique patterns\n",
    "    for i in range(len(unique_rows)):\n",
    "        print()\n",
    "        print ('    *** Working on unique pattern', i, ' ***')\n",
    "        print()\n",
    "        ## generate X_test subset that matches the unique pattern i\n",
    "        sub_X_test = pd.DataFrame()\n",
    "        sub_y_test = pd.Series(dtype=float)\n",
    "        for j in range(len(mask)): # check each row in mask\n",
    "            row_mask = np.array(mask.iloc[j])\n",
    "            if np.array_equal(row_mask, unique_rows[i]): # if the pattern matches the ith unique pattern\n",
    "                sub_X_test = sub_X_test.append(X_test.iloc[j])# append the according X_test row j to the subset\n",
    "                sub_y_test = sub_y_test.append(y_test.iloc[j])# append the according y_test row j\n",
    "                                                \n",
    "        sub_X_test = sub_X_test[X_test.columns[~unique_rows[i]]]\n",
    "        \n",
    "        ## choose the according reduced features for subgroups\n",
    "        sub_X_train = pd.DataFrame()\n",
    "        sub_Y_train = pd.DataFrame()\n",
    "        sub_X_CV = pd.DataFrame()\n",
    "        sub_y_CV = pd.DataFrame()\n",
    "        # 1.cut the feature columns that have nans in the according sub_X_test\n",
    "        sub_X_train = X_train[X_train.columns[~unique_rows[i]]]\n",
    "        sub_X_CV = X_CV[X_CV.columns[~unique_rows[i]]]\n",
    "        # 2.cut the rows in the sub_X_train and sub_X_CV that have any nans\n",
    "        sub_X_train = sub_X_train.dropna()\n",
    "        sub_X_CV = sub_X_CV.dropna()   \n",
    "        # 3.cut the sub_Y_train and sub_y_CV accordingly\n",
    "        sub_Y_train = Y_train.iloc[sub_X_train.index]\n",
    "        sub_y_CV = y_CV.iloc[sub_X_CV.index]\n",
    "        \n",
    "        # run XGB\n",
    "        sub_y_test_pred = xgb_model(sub_X_train, sub_Y_train, sub_X_CV, \n",
    "                                       sub_y_CV, sub_X_test, sub_y_test, i, verbose=4)\n",
    "        sub_y_test_pred = pd.DataFrame(sub_y_test_pred[1],columns=['sub_y_test_pred'],\n",
    "                                          index=sub_y_test.index)\n",
    "        print()\n",
    "        print('   Accuracy:', accuracy_score(sub_y_test,sub_y_test_pred))\n",
    "        print('   F1 Score:', f1_score(sub_y_test, sub_y_test_pred, average = 'macro' ))\n",
    "        \n",
    "        # collect the test predictions\n",
    "        all_y_test_pred = all_y_test_pred.append(sub_y_test_pred)\n",
    "        \n",
    "    # rank the final y_test_pred according to original y_test index\n",
    "    all_y_test_pred = all_y_test_pred.sort_index()\n",
    "    y_test = y_test.sort_index()\n",
    "               \n",
    "    # get global scores\n",
    "    total_accuracy = (accuracy_score(y_test,all_y_test_pred))\n",
    "    f1 = f1_score(y_test,all_y_test_pred, average = 'macro')\n",
    "    \n",
    "    cm = confusion_matrix\n",
    "    \n",
    "    return total_accuracy, f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ML_pipeline_ReducedFeatXGBoost_GridSearchCV(X, y, groups, i):\n",
    "    # create a test set based on groups\n",
    "    splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=i)\n",
    "    \n",
    "    # Get Test Set\n",
    "    for i_other,i_test in splitter.split(X, y, groups):\n",
    "        X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "    \n",
    "    # Get Validation Set\n",
    "    \n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    counter = 0\n",
    "    for i_train, i_test in kf.split(X_other, y_other, groups_other):\n",
    "        X_train, y_train, groups_train = X_other.iloc[i_train], y_other.iloc[i_train], groups_other.iloc[i_train]\n",
    "        X_val, y_val, groups_val = X_other.iloc[i_test], y_other.iloc[i_test], groups_other.iloc[i_test]\n",
    "        \n",
    "        #print(len(y_val))\n",
    "        #print(len(y_train))\n",
    "        counter = counter + 1\n",
    "        \n",
    "        print(f\"CV # {counter}\")\n",
    "        X_prep = preprocessor.fit_transform(X_train)\n",
    "        # collect feature names\n",
    "        \n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "        \n",
    "        df_train = pd.DataFrame(data=X_prep,columns=feature_names)\n",
    "        print(f\"Train Set Shape (after preprocessing): {df_train.shape}\")\n",
    "        print()\n",
    "        \n",
    "        # transform the CV\n",
    "        df_CV = preprocessor.transform(X_val)\n",
    "        df_CV = pd.DataFrame(data=df_CV,columns = feature_names)\n",
    "        print(f\"CV Set Shape (after preprocessing): {df_CV.shape}\")\n",
    "        print()\n",
    "        # transform the test\n",
    "        df_test = preprocessor.transform(X_test)\n",
    "        df_test = pd.DataFrame(data=df_test,columns = feature_names)\n",
    "        print(f\"Test Set Shape (after preprocessing): {df_test.shape}\")\n",
    "        print()\n",
    "        \n",
    "        y_CV = y_val\n",
    "        \n",
    "        total_accuracy, f1, cm = reduced_feature_xgb(df_train, y_train, df_CV, y_CV, df_test, y_test, i)\n",
    "        \n",
    "        return total_accuracy, f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State # 0\n",
      "\n",
      "CV # 1\n",
      "Train Set Shape (after preprocessing): (2808, 856)\n",
      "\n",
      "CV Set Shape (after preprocessing): (702, 856)\n",
      "\n",
      "Test Set Shape (after preprocessing): (694, 856)\n",
      "\n",
      "    There are 5 unique missing value patterns.\n",
      "\n",
      "\n",
      "    *** Working on unique pattern 0  ***\n",
      "\n",
      "Test set max score and best parameters are:\n",
      "0.8346894415911671\n",
      "[{'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 3, 'missing': nan, 'n_estimators': 10000, 'reg_alpha': 1.0, 'seed': 0, 'subsample': 0.7}]\n",
      "\n",
      "The CV F1 is: 0.18939393939393942\n",
      "\n",
      "The predictions are:\n",
      "[0 0 0 2 0 2 0 0 2 1 0 2 0 0 1 1 1 1 1 1 2 2 2 0 0 0 0 0 0 0 2 2 2 2 2 0 0\n",
      " 2 2 2 0 2 2 2 2 2 2 2 2 2 2 0 0 0 0 2 2 2 2 2 2 2 2 0 0 0 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 0 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "   Accuracy: 0.8210526315789474\n",
      "   F1 Score: 0.74022281590323\n",
      "\n",
      "    *** Working on unique pattern 1  ***\n",
      "\n",
      "Test set max score and best parameters are:\n",
      "0.7888722998409466\n",
      "[{'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 3, 'missing': nan, 'n_estimators': 10000, 'reg_alpha': 1.0, 'seed': 1, 'subsample': 0.7}]\n",
      "\n",
      "The CV F1 is: 0.16302765647743814\n",
      "\n",
      "The predictions are:\n",
      "[0 1 1 1 2 2 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0\n",
      " 2 2 1 1 2 2 2 1 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 1 1 1\n",
      " 0 2 2 0 0 0 0 0 2 2 2 2 2 0]\n",
      "\n",
      "\n",
      "   Accuracy: 0.7613636363636364\n",
      "   F1 Score: 0.7196231319038336\n",
      "\n",
      "    *** Working on unique pattern 2  ***\n",
      "\n",
      "Test set max score and best parameters are:\n",
      "0.6537205693854146\n",
      "[{'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 3, 'missing': nan, 'n_estimators': 10000, 'reg_alpha': 10.0, 'seed': 2, 'subsample': 0.7}]\n",
      "\n",
      "The CV F1 is: 0.17464315701091523\n",
      "\n",
      "The predictions are:\n",
      "[0 0 2 0 1 0 2 0 2 2 2 2 2 2 1 2 0 0 2 2 2 0 2 2 2 0 0 0 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 0 0 0 0 2 2 2 1 1 2 2 0 2 2 2 2 2 2 0 0 0 0 0 0 0 2 0 0 1 0 0 0 2\n",
      " 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 0 2 2 2 0 2 2 0 2 2 2 2 0\n",
      " 2 2 2 0 2 2 0 0 0 0 0 0 0 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 2 0 0\n",
      " 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "   Accuracy: 0.7756410256410257\n",
      "   F1 Score: 0.6142404190791287\n",
      "\n",
      "    *** Working on unique pattern 3  ***\n",
      "\n",
      "Test set max score and best parameters are:\n",
      "0.5775540944472123\n",
      "[{'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 3, 'missing': nan, 'n_estimators': 10000, 'reg_alpha': 10.0, 'seed': 3, 'subsample': 0.7}]\n",
      "\n",
      "The CV F1 is: 0.17777777777777778\n",
      "\n",
      "The predictions are:\n",
      "[0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 1 2 0 2 2 2 2 2 0 0 2 1\n",
      " 0 0 0 0 0 0 0 0 0 2 2 2 2 1 0 2 0 2 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 2 0\n",
      " 2 0 0 0 0 0 1 2 0 2 2 2 2 2 2 2 0 1 2 0 0 0 0 0 2 2 0 2 2 0 2 0 0 2 0 2 0\n",
      " 0 2 2 2 2 0 2 2 0 1 1 0 2 2 2 2 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 2 0 0\n",
      " 2 0 2 0 0 2 0 2 0 0 0 2 0 0 2 2 0 2 2 2 2 0 2 2 2 2 2 2 0 0 0 0 0 2 0 0 0\n",
      " 0 2 0 0 0 0 0 2 2 2 2 0 2 0 0 2 2 2 2 2 2 0 2 2 0 2 2 2 0 1]\n",
      "\n",
      "\n",
      "   Accuracy: 0.5674418604651162\n",
      "   F1 Score: 0.44084306098777315\n",
      "\n",
      "    *** Working on unique pattern 4  ***\n",
      "\n",
      "Test set max score and best parameters are:\n",
      "0.44710708575301844\n",
      "[{'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 3, 'missing': nan, 'n_estimators': 10000, 'reg_alpha': 0.01, 'seed': 4, 'subsample': 0.7}]\n",
      "\n",
      "The CV F1 is: 0.17247448081661387\n",
      "\n",
      "The predictions are:\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0\n",
      " 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 2\n",
      " 2 2 2 2 2 2 2 0 2 2 2 2 2 1 1 0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 2 2 0 0 2 0 0 0 0 2]\n",
      "\n",
      "\n",
      "   Accuracy: 0.5428571428571428\n",
      "   F1 Score: 0.43865602129075176\n",
      "f1 score: 0.3311500564763048\n",
      "\n",
      "test score: 0.33 +/- 0.0\n",
      "test score: 0.4 +/- 0.0\n",
      "CPU times: user 45min 4s, sys: 1min 2s, total: 46min 7s\n",
      "Wall time: 17min 49s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "best_grid_params = []\n",
    "confusion_mat = []\n",
    "#class_met = []\n",
    "\n",
    "for i in range(1):\n",
    "    print(f'Random State # {i}')\n",
    "    print()\n",
    "    \n",
    "    total_accuracy, f1, cm = ML_pipeline_ReducedFeatXGBoost_GridSearchCV(X, y, groups, i)\n",
    "    \n",
    "    confusion_mat.append(cm)\n",
    "    acc_scores.append(total_accuracy)\n",
    "    #class_met.append(class_metrics)\n",
    "    \n",
    "    #print(grid.best_params_)\n",
    "    \n",
    "    #best_grid_params.append(best_params)\n",
    "    #print()\n",
    "    #print('best CV score:',grid.best_score_)\n",
    "    #print()\n",
    "    print('f1 score:', f1)\n",
    "    f1_scores.append(f1)\n",
    "    print()\n",
    "    \n",
    "print('test score:',np.around(np.mean(f1_scores),2),'+/-',np.around(np.std(f1_scores),2))\n",
    "\n",
    "\n",
    "print('test score:',np.around(np.mean(acc_scores),2),'+/-',np.around(np.std(acc_scores),2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3746397694524496]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
