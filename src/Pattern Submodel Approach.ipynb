{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import xgboost\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "\n",
    "X_subsample2 = pd.read_csv('X_subsample_round2_split6.zip',compression='zip',index_col=False)\n",
    "y_subsample2 = pd.read_csv('y_subsample_round2_split6.zip',compression='zip')\n",
    "groups_subsample2 = pd.read_csv('groups_subsample_round2_split6.zip',compression='zip')\n",
    "\n",
    "X_subsample2 = X_subsample2.iloc[:,1:]\n",
    "y_subsample2 = y_subsample2.iloc[:,1:]\n",
    "groups_subsample2 = groups_subsample2.iloc[:,1:]\n",
    "\n",
    "y_subsample2_columns = y_subsample2.columns\n",
    "#y_subsample = y_subsample.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prscrbr_Type    Psychiatry\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_subsample2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_ftrs = ['Prscrbr_City',\n",
    "                    'Prscrbr_State_Abrvtn',\n",
    "                    'Brnd_Name',\n",
    "                    'Gnrc_Name']\n",
    "\n",
    "std_ftrs = ['Tot_Clms', \n",
    "            'Tot_30day_Fills', \n",
    "            'Tot_Day_Suply', \n",
    "            'Tot_Drug_Cst', \n",
    "            'Tot_Benes', \n",
    "            'GE65_Tot_Clms',\n",
    "            'GE65_Tot_30day_Fills',\n",
    "            'GE65_Tot_Drug_Cst',\n",
    "            'GE65_Tot_Day_Suply',\n",
    "            'GE65_Tot_Benes']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), categorical_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prscrbr_City</th>\n",
       "      <th>Prscrbr_State_Abrvtn</th>\n",
       "      <th>Brnd_Name</th>\n",
       "      <th>Gnrc_Name</th>\n",
       "      <th>Tot_Clms</th>\n",
       "      <th>Tot_30day_Fills</th>\n",
       "      <th>Tot_Day_Suply</th>\n",
       "      <th>Tot_Drug_Cst</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>GE65_Tot_Clms</th>\n",
       "      <th>GE65_Tot_30day_Fills</th>\n",
       "      <th>GE65_Tot_Drug_Cst</th>\n",
       "      <th>GE65_Tot_Day_Suply</th>\n",
       "      <th>GE65_Tot_Benes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4631 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prscrbr_City  Prscrbr_State_Abrvtn  Brnd_Name  Gnrc_Name  Tot_Clms  \\\n",
       "0            False                 False      False      False     False   \n",
       "1            False                 False      False      False     False   \n",
       "2            False                 False      False      False     False   \n",
       "3            False                 False      False      False     False   \n",
       "4            False                 False      False      False     False   \n",
       "...            ...                   ...        ...        ...       ...   \n",
       "4626         False                 False      False      False     False   \n",
       "4627         False                 False      False      False     False   \n",
       "4628         False                 False      False      False     False   \n",
       "4629         False                 False      False      False     False   \n",
       "4630         False                 False      False      False     False   \n",
       "\n",
       "      Tot_30day_Fills  Tot_Day_Suply  Tot_Drug_Cst  Tot_Benes  GE65_Tot_Clms  \\\n",
       "0               False          False         False       True          False   \n",
       "1               False          False         False       True           True   \n",
       "2               False          False         False       True          False   \n",
       "3               False          False         False       True           True   \n",
       "4               False          False         False       True           True   \n",
       "...               ...            ...           ...        ...            ...   \n",
       "4626            False          False         False       True          False   \n",
       "4627            False          False         False       True           True   \n",
       "4628            False          False         False      False          False   \n",
       "4629            False          False         False       True          False   \n",
       "4630            False          False         False       True           True   \n",
       "\n",
       "      GE65_Tot_30day_Fills  GE65_Tot_Drug_Cst  GE65_Tot_Day_Suply  \\\n",
       "0                    False              False               False   \n",
       "1                     True               True                True   \n",
       "2                    False              False               False   \n",
       "3                     True               True                True   \n",
       "4                     True               True                True   \n",
       "...                    ...                ...                 ...   \n",
       "4626                 False              False               False   \n",
       "4627                  True               True                True   \n",
       "4628                 False              False               False   \n",
       "4629                 False              False               False   \n",
       "4630                  True               True                True   \n",
       "\n",
       "      GE65_Tot_Benes  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3               True  \n",
       "4               True  \n",
       "...              ...  \n",
       "4626            True  \n",
       "4627            True  \n",
       "4628            True  \n",
       "4629            True  \n",
       "4630            True  \n",
       "\n",
       "[4631 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_subsample2.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14)\n",
      "[False False False False False False False False False False False False\n",
      " False False] 360\n",
      "[False False False False False False False False False False False False\n",
      " False  True] 575\n",
      "[False False False False False False False False False  True  True  True\n",
      "  True  True] 824\n",
      "[False False False False False False False False  True False False False\n",
      " False  True] 1754\n",
      "[False False False False False False False False  True  True  True  True\n",
      "  True  True] 1118\n"
     ]
    }
   ],
   "source": [
    "mask = X_subsample2.isnull()\n",
    "\n",
    "unique_rows, counts = np.unique(mask, axis=0, return_counts=True)\n",
    "print(unique_rows.shape) # 5 patterns, we will train 6 models\n",
    "\n",
    "for i in range(len(counts)):\n",
    "    print(unique_rows[i],counts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model(X_train, Y_train, X_CV, y_CV, X_test, y_test, i, verbose=4):\n",
    "\n",
    "    # make into row vectors to avoid an obnoxious sklearn/xgb warning\n",
    "    Y_train = np.reshape(np.array(Y_train), (1, -1)).ravel()\n",
    "    y_CV = np.reshape(np.array(y_CV), (1, -1)).ravel()\n",
    "    y_test = np.reshape(np.array(y_test), (1, -1)).ravel()\n",
    "\n",
    "    XGB = xgboost.XGBClassifier(num_class=3,\n",
    "                                #objective = \"multi:softprob\",\n",
    "                                eval_metric = 'merror', \n",
    "                                random_state = i, \n",
    "                                use_label_encoder = False)\n",
    "    \n",
    "    # find the best parameter set\n",
    "    param_grid = {\"learning_rate\": [0.01, 0.03],\n",
    "                  \"n_estimators\": [1000],\n",
    "                  \"seed\": [i],\n",
    "                  #\"reg_alpha\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                  \"reg_lambda\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "                  \"missing\": [np.nan], \n",
    "                  \"max_depth\": [1,3,10],\n",
    "                  \"colsample_bytree\": [0.9],              \n",
    "                  \"subsample\": [0.7, 0.9]}\n",
    "\n",
    "    pg = ParameterGrid(param_grid)\n",
    "\n",
    "    scores = np.zeros(len(pg))\n",
    "\n",
    "    weights = compute_sample_weight(class_weight='balanced', y = Y_train)\n",
    "    \n",
    "    for i in range(len(pg)):\n",
    "        if verbose >= 5:\n",
    "            print(\"Param set \" + str(i + 1) + \" / \" + str(len(pg)))\n",
    "        params = pg[i]\n",
    "        XGB.set_params(**params)\n",
    "        eval_set = [(X_CV, y_CV)]\n",
    "        XGB.fit(X_train, Y_train,\n",
    "                early_stopping_rounds=50, eval_set=eval_set, verbose=False,\n",
    "                sample_weight = weights)# with early stopping\n",
    "        y_CV_pred = XGB.predict(X_CV, iteration_range=(0, XGB.best_ntree_limit))\n",
    "        scores[i] = accuracy_score(y_CV,y_CV_pred)\n",
    "        scores_f1[i] = f1_score(y_CV,y_CV_pred)\n",
    "\n",
    "    best_params = np.array(pg)[scores == np.max(scores_f1)]\n",
    "    if verbose >= 4:\n",
    "        print('Test set max score and best parameters are:')\n",
    "        print(np.max(scores_f1))\n",
    "        print(best_params)\n",
    "        print()\n",
    "    # test the model on the test set with best parameter set\n",
    "    XGB.set_params(**best_params[0])\n",
    "    XGB.fit(X_train,Y_train,\n",
    "            early_stopping_rounds=50,eval_set=eval_set, verbose=False)\n",
    "    y_test_pred = XGB.predict(X_test, iteration_range=(0, XGB.best_ntree_limit))\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print ('The F1 is:',f1_score(y_CV,y_CV_pred))\n",
    "        print()\n",
    "    if verbose >= 2:\n",
    "        print ('The predictions are:')\n",
    "        print (y_test_pred)\n",
    "        print()\n",
    "    #if verbose >= 3:\n",
    "        #print(\"Feature importances:\")\n",
    "        #print(XGB.feature_importances_)\n",
    "\n",
    "    return (f1_score(y_CV,y_CV_pred), y_test_pred, XGB.feature_importances_ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Reduced-feature XGB model\n",
    "# all the inputs need to be pandas DataFrame\n",
    "def reduced_feature_xgb(X_train, Y_train, X_CV, y_CV, X_test, y_test, i):\n",
    "    \n",
    "    # find all unique patterns of missing value in test set\n",
    "    mask = X_test.isnull()\n",
    "    unique_rows = np.array(np.unique(mask, axis=0))\n",
    "    all_y_test_pred = pd.DataFrame()\n",
    "    \n",
    "    print('    There are', len(unique_rows), 'unique missing value patterns.')\n",
    "    print()\n",
    "    # divide test sets into subgroups according to the unique patterns\n",
    "    for i in range(len(unique_rows)):\n",
    "        print ('    *** Working on unique pattern', i, ' ***')\n",
    "        ## generate X_test subset that matches the unique pattern i\n",
    "        sub_X_test = pd.DataFrame()\n",
    "        sub_y_test = pd.Series(dtype=float)\n",
    "        for j in range(len(mask)): # check each row in mask\n",
    "            row_mask = np.array(mask.iloc[j])\n",
    "            if np.array_equal(row_mask, unique_rows[i]): # if the pattern matches the ith unique pattern\n",
    "                sub_X_test = sub_X_test.append(X_test.iloc[j])# append the according X_test row j to the subset\n",
    "                sub_y_test = sub_y_test.append(y_test.iloc[j])# append the according y_test row j\n",
    "                                                \n",
    "        sub_X_test = sub_X_test[X_test.columns[~unique_rows[i]]]\n",
    "        \n",
    "        ## choose the according reduced features for subgroups\n",
    "        sub_X_train = pd.DataFrame()\n",
    "        sub_Y_train = pd.DataFrame()\n",
    "        sub_X_CV = pd.DataFrame()\n",
    "        sub_y_CV = pd.DataFrame()\n",
    "        # 1.cut the feature columns that have nans in the according sub_X_test\n",
    "        sub_X_train = X_train[X_train.columns[~unique_rows[i]]]\n",
    "        sub_X_CV = X_CV[X_CV.columns[~unique_rows[i]]]\n",
    "        # 2.cut the rows in the sub_X_train and sub_X_CV that have any nans\n",
    "        sub_X_train = sub_X_train.dropna()\n",
    "        sub_X_CV = sub_X_CV.dropna()   \n",
    "        # 3.cut the sub_Y_train and sub_y_CV accordingly\n",
    "        sub_Y_train = Y_train.iloc[sub_X_train.index]\n",
    "        sub_y_CV = y_CV.iloc[sub_X_CV.index]\n",
    "        \n",
    "        # run XGB\n",
    "        sub_y_test_pred = xgb_model(sub_X_train, sub_Y_train, sub_X_CV, \n",
    "                                       sub_y_CV, sub_X_test, sub_y_test, i, verbose=4)\n",
    "        sub_y_test_pred = pd.DataFrame(sub_y_test_pred[1],columns=['sub_y_test_pred'],\n",
    "                                          index=sub_y_test.index)\n",
    "        print()\n",
    "        print('   Accuracy:', accuracy_score(sub_y_test,sub_y_test_pred))\n",
    "        print('   F1 Score:', f1_score(sub_y_test, sub_y_test_pred))\n",
    "        \n",
    "        # collect the test predictions\n",
    "        all_y_test_pred = all_y_test_pred.append(sub_y_test_pred)\n",
    "        \n",
    "    # rank the final y_test_pred according to original y_test index\n",
    "    all_y_test_pred = all_y_test_pred.sort_index()\n",
    "    y_test = y_test.sort_index()\n",
    "               \n",
    "    # get global scores\n",
    "    total_accuracy = (accuracy_score(y_test,all_y_test_pred))\n",
    "    f1 = (f1_score(y_test,all_y_test_pred))\n",
    "    \n",
    "    cm = confusion_matrix\n",
    "    \n",
    "    return total_accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set #1\n",
      "    Test Set Size: 927\n",
      "\n",
      "    Train Set #1 Size: 2778\n",
      "\n",
      "    Train Set Shape after preprocessing: (2778, 903)\n",
      "\n",
      "    Validation Set Shape after preprocessing: (926, 903)\n",
      "\n",
      "    Test Set Shape after preprocessing: (927, 903)\n",
      "\n",
      "    There are 5 unique missing value patterns.\n",
      "\n",
      "    *** Working on unique pattern 0  ***\n",
      "Test set max score and best parameters are:\n",
      "0.8441558441558441\n",
      "[{'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 1, 'missing': nan, 'n_estimators': 1000, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'seed': 0, 'subsample': 0.9}\n",
      " {'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 1, 'missing': nan, 'n_estimators': 1000, 'reg_alpha': 0.0, 'reg_lambda': 0.01, 'seed': 0, 'subsample': 0.9}\n",
      " {'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 1, 'missing': nan, 'n_estimators': 1000, 'reg_alpha': 0.01, 'reg_lambda': 0.0, 'seed': 0, 'subsample': 0.9}\n",
      " {'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 1, 'missing': nan, 'n_estimators': 1000, 'reg_alpha': 0.01, 'reg_lambda': 0.01, 'seed': 0, 'subsample': 0.9}]\n",
      "\n",
      "The accuracy is: 0.8529411764705882\n",
      "\n",
      "The predictions are:\n",
      "[0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 0 0 2 2 0 1 0 2 2 2 0 0 0 2 2 2 2 2 2\n",
      " 1 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 0 1 0]\n",
      "\n",
      "\n",
      "   Accuracy: 0.8529411764705882\n",
      "    *** Working on unique pattern 1  ***\n",
      "Test set max score and best parameters are:\n",
      "0.8895348837209303\n",
      "[{'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 10, 'missing': nan, 'n_estimators': 1000, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'seed': 1, 'subsample': 0.5}]\n",
      "\n",
      "The accuracy is: 0.8503937007874016\n",
      "\n",
      "The predictions are:\n",
      "[1 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "\n",
      "\n",
      "   Accuracy: 0.8503937007874016\n",
      "    *** Working on unique pattern 2  ***\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:111\u001b[0m\n",
      "Cell \u001b[0;32mIn [24], line 42\u001b[0m, in \u001b[0;36mreduced_feature_xgb\u001b[0;34m(X_train, Y_train, X_CV, y_CV, X_test, y_test, i)\u001b[0m\n\u001b[1;32m     39\u001b[0m sub_y_CV \u001b[38;5;241m=\u001b[39m y_CV\u001b[38;5;241m.\u001b[39miloc[sub_X_CV\u001b[38;5;241m.\u001b[39mindex]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# run XGB\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m sub_y_test_pred \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_Y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_X_CV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                               \u001b[49m\u001b[43msub_y_CV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_X_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_y_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m sub_y_test_pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(sub_y_test_pred[\u001b[38;5;241m1\u001b[39m],columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_y_test_pred\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     45\u001b[0m                                   index\u001b[38;5;241m=\u001b[39msub_y_test\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn [23], line 37\u001b[0m, in \u001b[0;36mxgb_model\u001b[0;34m(X_train, Y_train, X_CV, y_CV, X_test, y_test, i, verbose)\u001b[0m\n\u001b[1;32m     35\u001b[0m XGB\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m     36\u001b[0m eval_set \u001b[38;5;241m=\u001b[39m [(X_CV, y_CV)]\n\u001b[0;32m---> 37\u001b[0m \u001b[43mXGB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m# with early stopping\u001b[39;00m\n\u001b[1;32m     40\u001b[0m y_CV_pred \u001b[38;5;241m=\u001b[39m XGB\u001b[38;5;241m.\u001b[39mpredict(X_CV, iteration_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, XGB\u001b[38;5;241m.\u001b[39mbest_ntree_limit))\n\u001b[1;32m     41\u001b[0m scores[i] \u001b[38;5;241m=\u001b[39m accuracy_score(y_CV,y_CV_pred)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data1030/lib/python3.10/site-packages/xgboost/core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    505\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data1030/lib/python3.10/site-packages/xgboost/sklearn.py:1250\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1230\u001b[0m model, feval, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, eval_metric, params)\n\u001b[1;32m   1231\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1232\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1233\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     label_transform\u001b[38;5;241m=\u001b[39mlabel_transform,\n\u001b[1;32m   1248\u001b[0m )\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data1030/lib/python3.10/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data1030/lib/python3.10/site-packages/xgboost/training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data1030/lib/python3.10/site-packages/xgboost/core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1680\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import f1_score\n",
    "results = []\n",
    "f1_scores = []\n",
    "cm = []\n",
    "\n",
    "# label encoder for XGBoost\n",
    "le = LabelEncoder()\n",
    "y_subsample2 = le.fit_transform(y_subsample2)\n",
    "\n",
    "\n",
    "## Perform 60-20-20 Split\n",
    "# splitter for subsampled data\n",
    "stratGroupKFold2 = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "# splitter for other\n",
    "stratGroupKFold3 = StratifiedGroupKFold(n_splits=4)\n",
    "\n",
    "\n",
    "nr_states = [0,1,2] #,1,2\n",
    "counter = 0\n",
    "counter2 = 0\n",
    "final_models = []\n",
    "best_parameters = []\n",
    "\n",
    "for i_other2,i_test2 in stratGroupKFold2.split(X_subsample2.values, y_subsample2, groups_subsample2.values):\n",
    "    \n",
    "    counter = counter + 1\n",
    "    \n",
    "    X_other2, y_other2, groups_other2 = X_subsample2.values[i_other2], y_subsample2[i_other2], groups_subsample2.values[i_other2]\n",
    "    X_test, y_test, groups_test = X_subsample2.values[i_test2], y_subsample2[i_test2], groups_subsample2.values[i_test2]\n",
    "    \n",
    "    \n",
    "    # Reshape the data\n",
    "    \n",
    "    X_other2 = pd.DataFrame(X_other2)\n",
    "    X_other2.columns = X_subsample2.columns\n",
    "    \n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    X_test.columns = X_subsample2.columns\n",
    "\n",
    "    y_other2 = pd.DataFrame(y_other2)\n",
    "    y_other2.columns = y_subsample2_columns\n",
    "    \n",
    "    y_test = pd.DataFrame(y_test)\n",
    "    y_test.columns = y_subsample2_columns\n",
    "    \n",
    "    groups_other2 = pd.DataFrame(groups_other2)\n",
    "    groups_other2.columns = groups_subsample2.columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'Test Set #{counter}')\n",
    "\n",
    "    print(\"    Test Set Size:\", len(y_test))\n",
    "\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #for i in range(len(nr_states)):\n",
    "\n",
    "        #print(\"         Random State:\", i)\n",
    "        #print()\n",
    "        \n",
    "    counter2 = 0\n",
    "    \n",
    "    for i in range(len(nr_states)):\n",
    "    \n",
    "        for i_train3,i_val3 in stratGroupKFold3.split(X_other2.values, y_other2.values, groups_other2.values):\n",
    "            \n",
    "            counter2 = counter2 + 1\n",
    "\n",
    "            # Perform n-Fold CV\n",
    "            #cv = stratGroupKFold3.split(X_other2, y_other2, groups_other2)\n",
    "\n",
    "            X_train, y_train, groups_train = X_other2.iloc[i_train3], y_other2.iloc[i_train3], groups_other2.iloc[i_train3]\n",
    "            X_val, y_val, groups_val = X_other2.iloc[i_val3], y_other2.iloc[i_val3], groups_other2.iloc[i_val3]\n",
    "\n",
    "            print(f\"    Train Set #{counter2} Size: {len(X_train)}\")\n",
    "            print()\n",
    "\n",
    "\n",
    "            X_prep = preprocessor.fit_transform(X_train)\n",
    "\n",
    "            # collect feature names\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "            df_train = pd.DataFrame(data=X_prep,columns=feature_names)\n",
    "            print(f\"    Train Set Shape after preprocessing: {df_train.shape}\")\n",
    "            print()\n",
    "            \n",
    "            y_train = pd.DataFrame(y_train)\n",
    "            y_train.columns = y_subsample2_columns\n",
    "\n",
    "            # transform the CV\n",
    "            df_CV = preprocessor.transform(X_val)\n",
    "            df_CV = pd.DataFrame(data=df_CV,columns = feature_names)\n",
    "            print(f\"    Validation Set Shape after preprocessing: {df_CV.shape}\")\n",
    "            print()\n",
    "            \n",
    "            y_CV = pd.DataFrame(y_val)\n",
    "            y_CV.columns = y_subsample2_columns\n",
    "\n",
    "\n",
    "            # transform the test\n",
    "            df_test = preprocessor.transform(X_test)\n",
    "            df_test = pd.DataFrame(data=df_test,columns = feature_names)\n",
    "            print(f\"    Test Set Shape after preprocessing: {df_test.shape}\")\n",
    "            print()\n",
    "\n",
    "            \n",
    "\n",
    "            total_accuracy, f1, cm = reduced_feature_xgb(df_train, y_train, df_CV, y_CV, df_test, y_test, i)\n",
    "            results.append(total_accuracy)\n",
    "            \n",
    "            f1_scores.append(f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_scores = []\n",
    "best_params = []\n",
    "confusion_mat = []\n",
    "class_met = []\n",
    "\n",
    "for i in range(1):\n",
    "    print(f'Random State # {i}')\n",
    "    print()\n",
    "    \n",
    "    grid, score, cm, class_metrics = ML_pipeline_groups_GridSearchCV(X, y, groups, i*42, 2)\n",
    "    \n",
    "    confusion_mat.append(cm)\n",
    "    \n",
    "    class_met.append(class_metrics)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    \n",
    "    best_params.append(grid.best_params_)\n",
    "    print()\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print()\n",
    "    print('test score:', score)\n",
    "    test_scores.append(score)\n",
    "    print()\n",
    "    \n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
