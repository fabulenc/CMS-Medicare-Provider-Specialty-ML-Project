{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_ftrs = ['Prscrbr_City',\n",
    "                    'Prscrbr_State_Abrvtn',\n",
    "                    'Brnd_Name',\n",
    "                    'Gnrc_Name']\n",
    "\n",
    "std_ftrs = ['Tot_Clms', \n",
    "            'Tot_30day_Fills', \n",
    "            'Tot_Day_Suply', \n",
    "            'Tot_Drug_Cst', \n",
    "            'Tot_Benes', \n",
    "            'GE65_Tot_Clms',\n",
    "            'GE65_Tot_30day_Fills',\n",
    "            'GE65_Tot_Drug_Cst',\n",
    "            'GE65_Tot_Day_Suply',\n",
    "            'GE65_Tot_Benes']\n",
    "\n",
    "\n",
    "\n",
    "#clf = Pipeline(steps=[('preprocessor', preprocessor)])                                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "\n",
    "X_subsample2 = pd.read_csv('X_subsample_round2_split6.zip',compression='zip',index_col=False)\n",
    "y_subsample2 = pd.read_csv('y_subsample_round2_split6.zip',compression='zip')\n",
    "groups_subsample2 = pd.read_csv('groups_subsample_round2_split6.zip',compression='zip')\n",
    "\n",
    "X_subsample2 = X_subsample2.iloc[:,1:]\n",
    "y_subsample2 = y_subsample2.iloc[:,1:]\n",
    "groups_subsample2 = groups_subsample2.iloc[:,1:]\n",
    "\n",
    "y_subsample2_columns = y_subsample2.columns\n",
    "#y_subsample = y_subsample.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prscrbr_City</th>\n",
       "      <th>Prscrbr_State_Abrvtn</th>\n",
       "      <th>Brnd_Name</th>\n",
       "      <th>Gnrc_Name</th>\n",
       "      <th>Tot_Clms</th>\n",
       "      <th>Tot_30day_Fills</th>\n",
       "      <th>Tot_Day_Suply</th>\n",
       "      <th>Tot_Drug_Cst</th>\n",
       "      <th>Tot_Benes</th>\n",
       "      <th>GE65_Tot_Clms</th>\n",
       "      <th>GE65_Tot_30day_Fills</th>\n",
       "      <th>GE65_Tot_Drug_Cst</th>\n",
       "      <th>GE65_Tot_Day_Suply</th>\n",
       "      <th>GE65_Tot_Benes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>Aripiprazole</td>\n",
       "      <td>Aripiprazole</td>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>718</td>\n",
       "      <td>1198.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>Bupropion Xl</td>\n",
       "      <td>Bupropion Hcl</td>\n",
       "      <td>21</td>\n",
       "      <td>33.0</td>\n",
       "      <td>990</td>\n",
       "      <td>538.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>Clonazepam</td>\n",
       "      <td>Clonazepam</td>\n",
       "      <td>27</td>\n",
       "      <td>31.0</td>\n",
       "      <td>806</td>\n",
       "      <td>284.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>284.75</td>\n",
       "      <td>806.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>Clonidine Hcl</td>\n",
       "      <td>Clonidine Hcl</td>\n",
       "      <td>13</td>\n",
       "      <td>17.1</td>\n",
       "      <td>514</td>\n",
       "      <td>78.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>Duloxetine Hcl</td>\n",
       "      <td>Duloxetine Hcl</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>390</td>\n",
       "      <td>477.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>Boca Raton</td>\n",
       "      <td>FL</td>\n",
       "      <td>Vyvanse</td>\n",
       "      <td>Lisdexamfetamine Dimesylate</td>\n",
       "      <td>18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>540</td>\n",
       "      <td>5933.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627</th>\n",
       "      <td>Boca Raton</td>\n",
       "      <td>FL</td>\n",
       "      <td>Ziprasidone Hcl</td>\n",
       "      <td>Ziprasidone Hcl</td>\n",
       "      <td>49</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1770</td>\n",
       "      <td>2619.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>Boca Raton</td>\n",
       "      <td>FL</td>\n",
       "      <td>Zolpidem Tartrate</td>\n",
       "      <td>Zolpidem Tartrate</td>\n",
       "      <td>158</td>\n",
       "      <td>183.0</td>\n",
       "      <td>5490</td>\n",
       "      <td>1199.12</td>\n",
       "      <td>22.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1057.17</td>\n",
       "      <td>4380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>Estradiol</td>\n",
       "      <td>Estradiol</td>\n",
       "      <td>17</td>\n",
       "      <td>23.0</td>\n",
       "      <td>664</td>\n",
       "      <td>1930.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1930.07</td>\n",
       "      <td>664.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>Fluconazole</td>\n",
       "      <td>Fluconazole</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>80</td>\n",
       "      <td>65.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4631 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prscrbr_City Prscrbr_State_Abrvtn          Brnd_Name  \\\n",
       "0         Seattle                   WA       Aripiprazole   \n",
       "1         Seattle                   WA       Bupropion Xl   \n",
       "2         Seattle                   WA         Clonazepam   \n",
       "3         Seattle                   WA      Clonidine Hcl   \n",
       "4         Seattle                   WA     Duloxetine Hcl   \n",
       "...           ...                  ...                ...   \n",
       "4626   Boca Raton                   FL            Vyvanse   \n",
       "4627   Boca Raton                   FL    Ziprasidone Hcl   \n",
       "4628   Boca Raton                   FL  Zolpidem Tartrate   \n",
       "4629        Tampa                   FL          Estradiol   \n",
       "4630        Tampa                   FL        Fluconazole   \n",
       "\n",
       "                        Gnrc_Name  Tot_Clms  Tot_30day_Fills  Tot_Day_Suply  \\\n",
       "0                    Aripiprazole        24             24.0            718   \n",
       "1                   Bupropion Hcl        21             33.0            990   \n",
       "2                      Clonazepam        27             31.0            806   \n",
       "3                   Clonidine Hcl        13             17.1            514   \n",
       "4                  Duloxetine Hcl        13             13.0            390   \n",
       "...                           ...       ...              ...            ...   \n",
       "4626  Lisdexamfetamine Dimesylate        18             18.0            540   \n",
       "4627              Ziprasidone Hcl        49             59.0           1770   \n",
       "4628            Zolpidem Tartrate       158            183.0           5490   \n",
       "4629                    Estradiol        17             23.0            664   \n",
       "4630                  Fluconazole        17             17.0             80   \n",
       "\n",
       "      Tot_Drug_Cst  Tot_Benes  GE65_Tot_Clms  GE65_Tot_30day_Fills  \\\n",
       "0          1198.86        NaN            0.0                   0.0   \n",
       "1           538.93        NaN            NaN                   NaN   \n",
       "2           284.75        NaN           27.0                  31.0   \n",
       "3            78.13        NaN            NaN                   NaN   \n",
       "4           477.59        NaN            NaN                   NaN   \n",
       "...            ...        ...            ...                   ...   \n",
       "4626       5933.52        NaN            0.0                   0.0   \n",
       "4627       2619.93        NaN            NaN                   NaN   \n",
       "4628       1199.12       22.0          127.0                 146.0   \n",
       "4629       1930.07        NaN           17.0                  23.0   \n",
       "4630         65.65        NaN            NaN                   NaN   \n",
       "\n",
       "      GE65_Tot_Drug_Cst  GE65_Tot_Day_Suply  GE65_Tot_Benes  \n",
       "0                  0.00                 0.0             NaN  \n",
       "1                   NaN                 NaN             NaN  \n",
       "2                284.75               806.0             NaN  \n",
       "3                   NaN                 NaN             NaN  \n",
       "4                   NaN                 NaN             NaN  \n",
       "...                 ...                 ...             ...  \n",
       "4626               0.00                 0.0             NaN  \n",
       "4627                NaN                 NaN             NaN  \n",
       "4628            1057.17              4380.0             NaN  \n",
       "4629            1930.07               664.0             NaN  \n",
       "4630                NaN                 NaN             NaN  \n",
       "\n",
       "[4631 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_subsample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"xgbclassifier__subsample\": [0.5, 0.7, 0.9],\n",
    "              \"xgbclassifier__missing\": [np.nan],\n",
    "              \"xgbclassifier__max_depth\": [1, 3, 10],\n",
    "              \"xgbclassifier__learning_rate\": [0.001, 0.01, 0.1, 0.3],\n",
    "              \"xgbclassifier__n_estimators\": [1000],\n",
    "              \"xgbclassifier__gamma\": [1,5,10]}\n",
    "\n",
    "\n",
    "param_grid1 = {\"xgbclassifier__subsample\": [0.5, 0.7, 0.9],\n",
    "              \"xgbclassifier__missing\": [np.nan],\n",
    "              \"xgbclassifier__learning_rate\": [0.01],\n",
    "              \"xgbclassifier__max_depth\": [1],\n",
    "              \"xgbclassifier__gamma\": [5],\n",
    "              \"xgbclassifier__n_estimators\": [1000]}\n",
    "\n",
    "\n",
    "fit_params = {\"xgbclassifier__early_stopping_rounds\": 50}\n",
    "\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1_macro': make_scorer(f1_score, average = 'macro'),\n",
    "           'f1_weighted': make_scorer(f1_score, average = 'weighted')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_3specialties_equalWeight_subsample.zip',compression='zip', index_col=False)\n",
    "y = pd.read_csv('y_3specialties_equalWeight_subsample.zip',compression='zip')\n",
    "groups = pd.read_csv('groups_3specialties_equalWeight_subsample.zip',compression='zip')\n",
    "\n",
    "X = X.iloc[:,1:]\n",
    "y = y.iloc[:,1:]\n",
    "groups = groups.iloc[:,1:]\n",
    "\n",
    "y_columns = y.columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = y.values.ravel()\n",
    "y = le.fit_transform(y)\n",
    "y = pd.DataFrame(y)\n",
    "y.columns = y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for i_other,i_test in splitter.split(X, y, groups):\n",
    "    X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "    X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4204"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2822\n",
      "314\n",
      "3136\n",
      "2822\n",
      "314\n",
      "3136\n",
      "2822\n",
      "314\n",
      "3136\n",
      "2822\n",
      "314\n",
      "3136\n",
      "2822\n",
      "314\n",
      "3136\n",
      "2823\n",
      "313\n",
      "3136\n",
      "2823\n",
      "313\n",
      "3136\n",
      "2823\n",
      "313\n",
      "3136\n",
      "2822\n",
      "314\n",
      "3136\n",
      "2823\n",
      "313\n",
      "3136\n"
     ]
    }
   ],
   "source": [
    "group_kfold = GroupKFold(n_splits=10)\n",
    "\n",
    "for train_index, test_index in group_kfold.split(X_other, y_other, groups_other):\n",
    "    X_train, y_train, groups_train = X_other.iloc[train_index], y_other.iloc[train_index], groups_other.iloc[train_index]\n",
    "    X_val, y_val, groups_val = X_other.iloc[test_index], y_other.iloc[test_index], groups_other.iloc[test_index]\n",
    "    print(len(y_train))\n",
    "    print(len(y_val))\n",
    "    print(len(y_train)+len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function len(obj, /)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ML_pipeline_groups_GridSearchCV(X,y,groups,random_state,n_folds):\n",
    "    # create a test set based on groups\n",
    "    splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=random_state)\n",
    "    \n",
    "    for i_other,i_test in splitter.split(X, y, groups):\n",
    "        X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "        \n",
    "\n",
    "    # check the split\n",
    "#     print(pd.unique(groups))\n",
    "#     print(pd.unique(groups_other))\n",
    "#     print(pd.unique(groups_test))\n",
    "    # splitter for _other\n",
    "    kf = GroupKFold(n_splits=n_folds)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "\n",
    "    \n",
    "    clf = xgb.XGBClassifier(num_class=3,\n",
    "                                eval_metric = \"mlogloss\",\n",
    "                                objective = \"multi:softprob\",\n",
    "                                random_state = i, \n",
    "                                use_label_encoder = False)\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), categorical_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "    \n",
    "    pipe = make_pipeline(preprocessor,clf)\n",
    "    \n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {\"xgbclassifier__subsample\": [0.5, 0.7, 0.9],\n",
    "              \"xgbclassifier__missing\": [np.nan],\n",
    "              \"xgbclassifier__max_depth\": [1, 3, 10],\n",
    "              \"xgbclassifier__learning_rate\": [0.001, 0.01, 0.1, 0.3],\n",
    "              \"xgbclassifier__n_estimators\": [800, 1000],\n",
    "              \"xgbclassifier__gamma\": [1,5,10]}\n",
    "    \n",
    "    # prepare gridsearch\n",
    "    #grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        #cv=kf, return_train_score = True)\n",
    "    \n",
    "    grid = GridSearchCV(pipe, \n",
    "                            param_grid=param_grid,\n",
    "                            scoring = \"f1_macro\", #‘f1_macro’ #scorer #accuracy\n",
    "                            cv=kf, \n",
    "                            return_train_score = True, \n",
    "                            n_jobs=1, \n",
    "                            verbose=10)\n",
    "    \n",
    "    # do kfold CV on _other\n",
    "    grid_result = grid.fit(X_other, y_other, groups=groups_other)\n",
    "    \n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    \n",
    "    y_test_pred = grid.predict(X_test)\n",
    "    \n",
    "    #score = accuracy_score(y_test,y_test_pred)\n",
    "    \n",
    "    score = f1_score(y_test,y_test_pred, average = \"macro\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    class_metrics = metrics.classification_report(y_test, y_test_pred, digits=3)\n",
    "    \n",
    "    return grid, score, cm, class_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State # 0\n",
      "\n",
      "Fitting 2 folds for each of 216 candidates, totalling 432 fits\n",
      "[CV 1/2; 1/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 1/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.528, test=0.220) total time=   5.2s\n",
      "[CV 2/2; 1/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 1/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.499, test=0.235) total time=   6.3s\n",
      "[CV 1/2; 2/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 2/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.527, test=0.220) total time=   6.7s\n",
      "[CV 2/2; 2/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 2/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.507, test=0.240) total time=   7.1s\n",
      "[CV 1/2; 3/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 3/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.527, test=0.218) total time=   8.1s\n",
      "[CV 2/2; 3/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 3/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.507, test=0.240) total time=   7.8s\n",
      "[CV 1/2; 4/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 4/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.542, test=0.229) total time=   7.5s\n",
      "[CV 2/2; 4/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 4/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.503, test=0.236) total time=   7.9s\n",
      "[CV 1/2; 5/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 5/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.529, test=0.220) total time=   8.7s\n",
      "[CV 2/2; 5/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 5/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.508, test=0.241) total time=   9.2s\n",
      "[CV 1/2; 6/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 6/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.528, test=0.220) total time=   9.4s\n",
      "[CV 2/2; 6/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 6/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.508, test=0.241) total time=   9.9s\n",
      "[CV 1/2; 7/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 7/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.815, test=0.482) total time=  15.1s\n",
      "[CV 2/2; 7/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 7/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.689, test=0.333) total time=  16.1s\n",
      "[CV 1/2; 8/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 8/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.803, test=0.480) total time=  19.6s\n",
      "[CV 2/2; 8/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 8/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.672, test=0.305) total time=  23.4s\n",
      "[CV 1/2; 9/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 9/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.792, test=0.472) total time=  23.2s\n",
      "[CV 2/2; 9/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 9/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.663, test=0.306) total time=  23.5s\n",
      "[CV 1/2; 10/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 10/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.826, test=0.485) total time=  23.8s\n",
      "[CV 2/2; 10/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 10/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.712, test=0.349) total time=  25.1s\n",
      "[CV 1/2; 11/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 11/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.810, test=0.484) total time=  26.7s\n",
      "[CV 2/2; 11/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 11/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.701, test=0.329) total time=  25.4s\n",
      "[CV 1/2; 12/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 12/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.808, test=0.484) total time=  28.4s\n",
      "[CV 2/2; 12/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 12/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.694, test=0.328) total time=  30.5s\n",
      "[CV 1/2; 13/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 13/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.978, test=0.532) total time=  46.6s\n",
      "[CV 2/2; 13/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 13/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.986, test=0.373) total time=  49.1s\n",
      "[CV 1/2; 14/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 14/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.975, test=0.539) total time=  54.6s\n",
      "[CV 2/2; 14/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 14/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.985, test=0.384) total time= 1.0min\n",
      "[CV 1/2; 15/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 15/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.968, test=0.516) total time= 1.0min\n",
      "[CV 2/2; 15/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 15/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.986, test=0.393) total time= 1.1min\n",
      "[CV 1/2; 16/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 16/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.977, test=0.544) total time= 1.0min\n",
      "[CV 2/2; 16/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 16/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.986, test=0.379) total time= 1.2min\n",
      "[CV 1/2; 17/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 17/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.977, test=0.550) total time= 1.2min\n",
      "[CV 2/2; 17/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 17/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.985, test=0.381) total time= 1.3min\n",
      "[CV 1/2; 18/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 18/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.974, test=0.536) total time= 1.7min\n",
      "[CV 2/2; 18/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 18/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.983, test=0.381) total time= 1.6min\n",
      "[CV 1/2; 19/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 19/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.848, test=0.365) total time=   6.5s\n",
      "[CV 2/2; 19/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 19/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.803, test=0.350) total time=   7.0s\n",
      "[CV 1/2; 20/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 20/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.850, test=0.365) total time=   7.7s\n",
      "[CV 2/2; 20/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 20/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.800, test=0.353) total time=   8.7s\n",
      "[CV 1/2; 21/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 21/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.852, test=0.370) total time=   8.7s\n",
      "[CV 2/2; 21/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 21/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.798, test=0.347) total time=   9.3s\n",
      "[CV 1/2; 22/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 22/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.895, test=0.471) total time=   8.5s\n",
      "[CV 2/2; 22/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 22/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.885, test=0.368) total time=   9.2s\n",
      "[CV 1/2; 23/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 23/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.897, test=0.414) total time=   9.3s\n",
      "[CV 2/2; 23/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 23/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.889, test=0.373) total time=  10.0s\n",
      "[CV 1/2; 24/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 24/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.891, test=0.376) total time=  11.0s\n",
      "[CV 2/2; 24/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 24/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.887, test=0.377) total time=  11.8s\n",
      "[CV 1/2; 25/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 25/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.978, test=0.557) total time=  17.8s\n",
      "[CV 2/2; 25/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 25/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.993, test=0.388) total time=  18.9s\n",
      "[CV 1/2; 26/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 26/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.975, test=0.554) total time=  21.4s\n",
      "[CV 2/2; 26/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 26/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.995, test=0.391) total time=  22.7s\n",
      "[CV 1/2; 27/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 27/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.975, test=0.555) total time=  25.6s\n",
      "[CV 2/2; 27/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 27/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.995, test=0.380) total time=  26.5s\n",
      "[CV 1/2; 28/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 28/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.983, test=0.549) total time=  25.1s\n",
      "[CV 2/2; 28/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 28/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.996, test=0.376) total time= 1.3min\n",
      "[CV 1/2; 29/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 29/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.983, test=0.551) total time= 1.4min\n",
      "[CV 2/2; 29/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 29/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.996, test=0.373) total time= 1.6min\n",
      "[CV 1/2; 30/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 30/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.984, test=0.551) total time= 1.7min\n",
      "[CV 2/2; 30/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 30/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.996, test=0.357) total time= 1.7min\n",
      "[CV 1/2; 31/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 31/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.996, test=0.470) total time= 3.5min\n",
      "[CV 2/2; 31/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 31/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=1.000, test=0.282) total time= 3.4min\n",
      "[CV 1/2; 32/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 32/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.997, test=0.475) total time= 3.8min\n",
      "[CV 2/2; 32/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 32/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=1.000, test=0.235) total time= 3.9min\n",
      "[CV 1/2; 33/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 33/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.996, test=0.470) total time= 4.0min\n",
      "[CV 2/2; 33/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 33/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=1.000, test=0.245) total time= 4.0min\n",
      "[CV 1/2; 34/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 34/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.997, test=0.466) total time= 4.5min\n",
      "[CV 2/2; 34/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 34/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=1.000, test=0.288) total time= 4.2min\n",
      "[CV 1/2; 35/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 35/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.997, test=0.472) total time= 5.0min\n",
      "[CV 2/2; 35/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 35/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=1.000, test=0.234) total time= 4.9min\n",
      "[CV 1/2; 36/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 36/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.996, test=0.463) total time= 5.2min\n",
      "[CV 2/2; 36/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 36/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=1.000, test=0.241) total time= 3.3min\n",
      "[CV 1/2; 37/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 37/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.994, test=0.480) total time=   8.5s\n",
      "[CV 2/2; 37/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 37/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.999, test=0.300) total time=   8.6s\n",
      "[CV 1/2; 38/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 38/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.994, test=0.456) total time=   9.7s\n",
      "[CV 2/2; 38/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 38/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.999, test=0.269) total time=   9.7s\n",
      "[CV 1/2; 39/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 39/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.992, test=0.424) total time=  10.1s\n",
      "[CV 2/2; 39/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 39/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.256) total time=  10.5s\n",
      "[CV 1/2; 40/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 40/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.994, test=0.476) total time=   9.8s\n",
      "[CV 2/2; 40/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 40/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.999, test=0.305) total time=  10.4s\n",
      "[CV 1/2; 41/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 41/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.994, test=0.447) total time=  11.5s\n",
      "[CV 2/2; 41/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 41/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.999, test=0.258) total time=  12.0s\n",
      "[CV 1/2; 42/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 42/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.994, test=0.419) total time=  12.8s\n",
      "[CV 2/2; 42/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 42/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.241) total time=  15.7s\n",
      "[CV 1/2; 43/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 43/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.995, test=0.503) total time=  27.2s\n",
      "[CV 2/2; 43/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 43/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=1.000, test=0.433) total time=  21.1s\n",
      "[CV 1/2; 44/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 44/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.995, test=0.498) total time=  25.8s\n",
      "[CV 2/2; 44/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 44/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=1.000, test=0.354) total time=  28.8s\n",
      "[CV 1/2; 45/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 45/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.996, test=0.483) total time=  24.7s\n",
      "[CV 2/2; 45/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 45/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.277) total time=  25.3s\n",
      "[CV 1/2; 46/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 46/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.996, test=0.504) total time=  23.7s\n",
      "[CV 2/2; 46/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 46/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=1.000, test=0.429) total time=  24.2s\n",
      "[CV 1/2; 47/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 47/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.995, test=0.497) total time=  26.8s\n",
      "[CV 2/2; 47/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 47/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=1.000, test=0.354) total time=  28.8s\n",
      "[CV 1/2; 48/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 48/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.996, test=0.483) total time=  31.6s\n",
      "[CV 2/2; 48/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 48/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.276) total time=  33.4s\n",
      "[CV 1/2; 49/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 49/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.998, test=0.460) total time= 1.0min\n",
      "[CV 2/2; 49/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 49/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=1.000, test=0.316) total time=  58.2s\n",
      "[CV 1/2; 50/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 50/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.998, test=0.462) total time=  59.7s\n",
      "[CV 2/2; 50/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 50/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=1.000, test=0.241) total time= 1.2min\n",
      "[CV 1/2; 51/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 51/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.998, test=0.445) total time= 1.2min\n",
      "[CV 2/2; 51/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 51/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.250) total time= 1.3min\n",
      "[CV 1/2; 52/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 52/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.998, test=0.462) total time= 1.1min\n",
      "[CV 2/2; 52/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 52/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=1.000, test=0.318) total time= 1.4min\n",
      "[CV 1/2; 53/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 53/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.998, test=0.461) total time= 1.4min\n",
      "[CV 2/2; 53/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 53/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=1.000, test=0.241) total time= 1.4min\n",
      "[CV 1/2; 54/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 54/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.998, test=0.444) total time= 1.7min\n",
      "[CV 2/2; 54/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 54/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.1, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.250) total time= 2.1min\n",
      "[CV 1/2; 55/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 55/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.994, test=0.479) total time=  12.1s\n",
      "[CV 2/2; 55/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 55/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.999, test=0.322) total time=  10.4s\n",
      "[CV 1/2; 56/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 56/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.994, test=0.450) total time=  10.9s\n",
      "[CV 2/2; 56/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 56/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.999, test=0.281) total time=  17.6s\n",
      "[CV 1/2; 57/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 57/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.994, test=0.430) total time=  19.5s\n",
      "[CV 2/2; 57/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 57/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.236) total time=  19.2s\n",
      "[CV 1/2; 58/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 58/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.995, test=0.479) total time=  18.1s\n",
      "[CV 2/2; 58/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 58/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.999, test=0.322) total time=  11.4s\n",
      "[CV 1/2; 59/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 59/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.994, test=0.439) total time=  14.5s\n",
      "[CV 2/2; 59/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 59/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.999, test=0.278) total time=  15.5s\n",
      "[CV 1/2; 60/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 60/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.994, test=0.429) total time=  26.2s\n",
      "[CV 2/2; 60/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 60/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.240) total time=  24.4s\n",
      "[CV 1/2; 61/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 61/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.997, test=0.492) total time=  19.0s\n",
      "[CV 2/2; 61/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 61/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=1.000, test=0.424) total time=  19.9s\n",
      "[CV 1/2; 62/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 62/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.997, test=0.496) total time=  22.2s\n",
      "[CV 2/2; 62/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 62/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=1.000, test=0.390) total time=  23.9s\n",
      "[CV 1/2; 63/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 63/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.997, test=0.483) total time=  25.7s\n",
      "[CV 2/2; 63/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 63/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.277) total time=  27.1s\n",
      "[CV 1/2; 64/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 64/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.997, test=0.493) total time=  25.5s\n",
      "[CV 2/2; 64/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 64/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=1.000, test=0.420) total time=  26.5s\n",
      "[CV 1/2; 65/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 65/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.997, test=0.494) total time=  28.8s\n",
      "[CV 2/2; 65/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 65/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=1.000, test=0.389) total time=  31.4s\n",
      "[CV 1/2; 66/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 66/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.997, test=0.482) total time=  35.6s\n",
      "[CV 2/2; 66/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 66/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.277) total time=  42.1s\n",
      "[CV 1/2; 67/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 67/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.997, test=0.478) total time= 1.4min\n",
      "[CV 2/2; 67/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 67/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=1.000, test=0.324) total time= 1.8min\n",
      "[CV 1/2; 68/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 68/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.998, test=0.465) total time= 2.0min\n",
      "[CV 2/2; 68/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 68/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=1.000, test=0.234) total time= 1.5min\n",
      "[CV 1/2; 69/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 69/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.456) total time= 1.2min\n",
      "[CV 2/2; 69/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 69/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.244) total time= 1.4min\n",
      "[CV 1/2; 70/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 70/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.999, test=0.483) total time= 1.5min\n",
      "[CV 2/2; 70/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 70/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=1.000, test=0.325) total time= 1.8min\n",
      "[CV 1/2; 71/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 71/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.998, test=0.467) total time= 2.0min\n",
      "[CV 2/2; 71/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 71/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=1.000, test=0.234) total time= 1.9min\n",
      "[CV 1/2; 72/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 72/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.455) total time= 2.1min\n",
      "[CV 2/2; 72/216] START xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 72/216] END xgbclassifier__gamma=1, xgbclassifier__learning_rate=0.3, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.999, test=0.244) total time= 2.1min\n",
      "[CV 1/2; 73/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 73/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.528, test=0.220) total time=   7.3s\n",
      "[CV 2/2; 73/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 73/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.499, test=0.235) total time=   7.6s\n",
      "[CV 1/2; 74/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 74/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.527, test=0.220) total time=   8.0s\n",
      "[CV 2/2; 74/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 74/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.507, test=0.240) total time=   8.5s\n",
      "[CV 1/2; 75/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 75/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.527, test=0.218) total time=   8.8s\n",
      "[CV 2/2; 75/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 75/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.507, test=0.240) total time=   9.5s\n",
      "[CV 1/2; 76/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 76/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.542, test=0.229) total time=   8.7s\n",
      "[CV 2/2; 76/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 76/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.503, test=0.236) total time=   9.2s\n",
      "[CV 1/2; 77/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 77/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.529, test=0.220) total time=  10.3s\n",
      "[CV 2/2; 77/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 77/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.508, test=0.241) total time=  10.9s\n",
      "[CV 1/2; 78/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 78/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.528, test=0.220) total time=  11.5s\n",
      "[CV 2/2; 78/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 78/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.508, test=0.241) total time=  12.5s\n",
      "[CV 1/2; 79/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 79/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.815, test=0.481) total time=  18.9s\n",
      "[CV 2/2; 79/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 79/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.689, test=0.329) total time=  19.4s\n",
      "[CV 1/2; 80/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 80/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.802, test=0.475) total time=  21.8s\n",
      "[CV 2/2; 80/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 80/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.667, test=0.305) total time=  24.7s\n",
      "[CV 1/2; 81/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 81/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.790, test=0.469) total time=  26.5s\n",
      "[CV 2/2; 81/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 81/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.663, test=0.306) total time=  43.7s\n",
      "[CV 1/2; 82/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 82/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.826, test=0.483) total time=  28.5s\n",
      "[CV 2/2; 82/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 82/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.711, test=0.350) total time=  26.3s\n",
      "[CV 1/2; 83/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 83/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.812, test=0.482) total time=  35.5s\n",
      "[CV 2/2; 83/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 83/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.700, test=0.327) total time=  38.9s\n",
      "[CV 1/2; 84/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 84/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.807, test=0.484) total time=  39.1s\n",
      "[CV 2/2; 84/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 84/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.694, test=0.328) total time=  44.0s\n",
      "[CV 1/2; 85/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 85/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.970, test=0.520) total time= 1.4min\n",
      "[CV 2/2; 85/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 85/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.984, test=0.344) total time= 1.4min\n",
      "[CV 1/2; 86/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 86/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.972, test=0.531) total time= 1.9min\n",
      "[CV 2/2; 86/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 86/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.984, test=0.330) total time= 1.8min\n",
      "[CV 1/2; 87/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 87/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.964, test=0.511) total time= 2.8min\n",
      "[CV 2/2; 87/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 87/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.987, test=0.305) total time= 1.6min\n",
      "[CV 1/2; 88/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 88/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.970, test=0.532) total time= 1.3min\n",
      "[CV 2/2; 88/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 88/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.986, test=0.350) total time= 1.2min\n",
      "[CV 1/2; 89/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 89/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.971, test=0.542) total time= 1.5min\n",
      "[CV 2/2; 89/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 89/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.985, test=0.338) total time= 1.9min\n",
      "[CV 1/2; 90/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 90/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.968, test=0.532) total time= 2.5min\n",
      "[CV 2/2; 90/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 90/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.001, xgbclassifier__max_depth=10, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.982, test=0.361) total time= 2.9min\n",
      "[CV 1/2; 91/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 91/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.848, test=0.365) total time=  19.0s\n",
      "[CV 2/2; 91/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 91/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.803, test=0.350) total time=  13.4s\n",
      "[CV 1/2; 92/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 92/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.850, test=0.365) total time=  16.7s\n",
      "[CV 2/2; 92/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 92/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.800, test=0.353) total time=  28.5s\n",
      "[CV 1/2; 93/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 93/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.852, test=0.370) total time=  28.4s\n",
      "[CV 2/2; 93/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 93/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.798, test=0.347) total time=  11.7s\n",
      "[CV 1/2; 94/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 94/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.895, test=0.471) total time=  11.6s\n",
      "[CV 2/2; 94/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 94/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.885, test=0.368) total time=  11.6s\n",
      "[CV 1/2; 95/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 95/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.897, test=0.414) total time=  12.4s\n",
      "[CV 2/2; 95/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 95/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.7;, score=(train=0.889, test=0.373) total time=  13.7s\n",
      "[CV 1/2; 96/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 96/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.891, test=0.376) total time=  14.4s\n",
      "[CV 2/2; 96/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 96/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=1, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.9;, score=(train=0.887, test=0.377) total time=  15.1s\n",
      "[CV 1/2; 97/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 97/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.970, test=0.540) total time=  26.5s\n",
      "[CV 2/2; 97/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5\n",
      "[CV 2/2; 97/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.5;, score=(train=0.990, test=0.365) total time=  28.6s\n",
      "[CV 1/2; 98/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 1/2; 98/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.974, test=0.548) total time=  31.1s\n",
      "[CV 2/2; 98/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7\n",
      "[CV 2/2; 98/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.7;, score=(train=0.993, test=0.377) total time=  31.7s\n",
      "[CV 1/2; 99/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 1/2; 99/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.974, test=0.553) total time=  35.0s\n",
      "[CV 2/2; 99/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9\n",
      "[CV 2/2; 99/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=800, xgbclassifier__subsample=0.9;, score=(train=0.995, test=0.377) total time=  38.3s\n",
      "[CV 1/2; 100/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n",
      "[CV 1/2; 100/216] END xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5;, score=(train=0.972, test=0.534) total time=  39.3s\n",
      "[CV 2/2; 100/216] START xgbclassifier__gamma=5, xgbclassifier__learning_rate=0.01, xgbclassifier__max_depth=3, xgbclassifier__missing=nan, xgbclassifier__n_estimators=1000, xgbclassifier__subsample=0.5\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_scores = []\n",
    "best_params = []\n",
    "confusion_mat = []\n",
    "class_met = []\n",
    "\n",
    "for i in range(1):\n",
    "    print(f'Random State # {i}')\n",
    "    print()\n",
    "    \n",
    "    grid, score, cm, class_metrics = ML_pipeline_groups_GridSearchCV(X, y, groups, i*42, 2)\n",
    "    \n",
    "    confusion_mat.append(cm)\n",
    "    \n",
    "    class_met.append(class_metrics)\n",
    "    \n",
    "    print(grid.best_params_)\n",
    "    \n",
    "    best_params.append(grid.best_params_)\n",
    "    print()\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print()\n",
    "    print('test score:', score)\n",
    "    test_scores.append(score)\n",
    "    print()\n",
    "    \n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ML_pipeline_XGBoost_ParamGrid(X, y, groups, i):\n",
    "    # create a test set based on groups\n",
    "    splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=i)\n",
    "    \n",
    "    # Get Test Set\n",
    "    for i_other,i_test in splitter.split(X, y, groups):\n",
    "        X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "    \n",
    "    # Get Validation Set\n",
    "    \n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    counter = 0\n",
    "    for i_train, i_test in kf.split(X_other, y_other, groups_other):\n",
    "        X_train, y_train, groups_train = X_other.iloc[i_train], y_other.iloc[i_train], groups_other.iloc[i_train]\n",
    "        X_val, y_val, groups_val = X_other.iloc[i_test], y_other.iloc[i_test], groups_other.iloc[i_test]\n",
    "        \n",
    "        #print(len(y_val))\n",
    "        #print(len(y_train))\n",
    "        counter = counter + 1\n",
    "        \n",
    "        print(f\"CV # {counter}\")\n",
    "        X_prep = preprocessor.fit_transform(X_train)\n",
    "        # collect feature names\n",
    "        \n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "        \n",
    "        df_train = pd.DataFrame(data=X_prep,columns=feature_names)\n",
    "        print(f\"Train Set Shape (after preprocessing): {df_train.shape}\")\n",
    "        print()\n",
    "        \n",
    "        # transform the CV\n",
    "        df_CV = preprocessor.transform(X_val)\n",
    "        df_CV = pd.DataFrame(data=df_CV,columns = feature_names)\n",
    "        print(f\"CV Set Shape (after preprocessing): {df_CV.shape}\")\n",
    "        print()\n",
    "        # transform the test\n",
    "        df_test = preprocessor.transform(X_test)\n",
    "        df_test = pd.DataFrame(data=df_test,columns = feature_names)\n",
    "        print(f\"Test Set Shape (after preprocessing): {df_test.shape}\")\n",
    "        print()\n",
    "        \n",
    "        y_CV = y_val\n",
    "        \n",
    "        total_accuracy, f1, cm = reduced_feature_xgb(df_train, y_train, df_CV, y_CV, df_test, y_test, i)\n",
    "        \n",
    "        return total_accuracy, f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n%%time\\n\\n## Perform 60-20-20 Split\\n# splitter for subsampled data\\nstratGroupKFold2 = StratifiedGroupKFold(n_splits=5)\\n\\n# splitter for other\\nstratGroupKFold3 = StratifiedGroupKFold(n_splits=4)\\n\\n# label encoder for XGBoost\\nle = LabelEncoder()\\ny_subsample2 = le.fit_transform(y_subsample2)\\n\\n# Initialize lists\\nnr_states = [0,1,2] # ,1,2\\ntest_scores = []\\nfinal_models = []\\nbest_params = []\\ntest_scores = []\\ncounter = 0\\n\\n# num of lists should equal number of test sets that the StratifiedGroupKFold will generate\\n# each list should contain entries with the same number of random state\\n    \\nlist1_params = []\\nlist1_grid = []\\nlist1_pred = []\\nlist1_score = []\\nlist1_means = []\\nlist1_cm = []\\nlist1_stds = []\\nlist1_metrics = []\\n\\nlist1_f1 = []\\n\\nlist2_params = []\\nlist2_grid = []\\nlist2_pred = []\\nlist2_score = []\\nlist2_means = []\\nlist2_stds = []\\nlist2_cm = []\\nlist2_ytest = []\\nlist2_metrics = []\\nlist2_f1 = []\\n\\nlist3_params = []\\nlist3_grid = []\\nlist3_pred = []\\nlist3_score = []\\nlist3_means = []\\nlist3_stds = []\\nlist3_cm = []\\nlist3_metrics = []\\nlist3_f1 = []\\n\\nlist4_params = []\\nlist4_grid = []\\nlist4_pred = []\\nlist4_score = []\\nlist4_means = []\\nlist4_stds = []\\nlist4_cm = []\\nlist4_metrics = []\\nlist4_f1 = []\\n\\nlist5_params = []\\nlist5_grid = []\\nlist5_pred = []\\nlist5_score = []\\nlist5_means = []\\nlist5_stds = []\\nlist5_cm = []\\nlist5_metrics = []\\nlist5_f1 = []\\n\\nfor i_other2,i_test2 in stratGroupKFold2.split(X_subsample2.values, y_subsample2, groups_subsample2.values):\\n    \\n    counter = counter + 1\\n    \\n    X_other2, y_other2, groups_other2 = X_subsample2.values[i_other2], y_subsample2[i_other2], groups_subsample2.values[i_other2]\\n    X_test2, y_test2, groups_test2 = X_subsample2.values[i_test2], y_subsample2[i_test2], groups_subsample2.values[i_test2]\\n\\n    # Reshape the data\\n    \\n    X_other2 = pd.DataFrame(X_other2)\\n    X_other2.columns = X_subsample2.columns\\n    \\n    X_test2 = pd.DataFrame(X_test2)\\n    X_test2.columns = X_subsample2.columns\\n\\n    y_other2 = pd.DataFrame(y_other2)\\n    y_other2.columns = y_subsample2_columns\\n    \\n\\n    groups_other2 = pd.DataFrame(groups_other2)\\n    groups_other2.columns = groups_subsample2.columns\\n\\n    y_other2 = np.reshape(np.array(y_other2), (1, -1)).ravel()\\n    \\n    \\n    y_test2 = np.reshape(np.array(y_test2), (1, -1)).ravel()\\n    \\n    \\n    \\n    print(f\\'Test Set #{counter}\\')\\n\\n    print(\"    Test Set Size:\", len(y_test2))\\n    \\n    print(\"    X_test Shape:\", X_test2.shape)\\n\\n    print()\\n    \\n    for i in range(len(nr_states)):\\n\\n        print(\"         Random State:\", i)\\n        print()\\n\\n        # Perform n-Fold CV\\n        cv = stratGroupKFold3.split(X_other2, y_other2, groups_other2)\\n\\n\\n        # Initialize XGBoost Classifier\\n        clf = xgb.XGBClassifier(num_class=3,\\n                                eval_metric = \"mlogloss\",\\n                                objective = \"multi:softprob\",\\n                                random_state = i, \\n                                use_label_encoder = False)\\n\\n        pipe = make_pipeline(preprocessor,clf)\\n\\n        grid = GridSearchCV(pipe, \\n                            param_grid=param_grid,\\n                            scoring = \"f1_macro\", #‘f1_macro’ #scorer #accuracy\\n                            cv=cv, \\n                            return_train_score = True, \\n                            n_jobs=1, \\n                            verbose=10)\\n        \\n        # Compute sample weights\\n        weights = compute_sample_weight(class_weight=\\'balanced\\', y = y_other2)\\n        \\n        print(f\\'Feature weights: {np.unique(weights)}\\')\\n\\n        grid_result = grid.fit(X_other2, y_other2, groups = groups_other2,\\n                              xgbclassifier__sample_weight = weights) #xgbclassifier__early_stopping_rounds=50\\n        \\n        print()\\n        print(\\'best model parameters:\\', grid.best_params_)\\n\\n        print()\\n\\n        print(\\'validation score:\\',grid.best_score_)\\n        \\n        print()\\n        \\n        means = grid_result.cv_results_[\\'mean_test_score\\']\\n        stds = grid_result.cv_results_[\\'std_test_score\\']\\n        \\n        y_test_pred = grid.predict(X_test2)\\n        score = accuracy_score(y_test2,y_test_pred)\\n        cm = confusion_matrix(y_test2, y_test_pred)\\n        f1 = f1_score(y_test2, y_test_pred)\\n        class_metrics = metrics.classification_report(y_test2, y_test_pred, digits=3)\\n        \\n        print(\\'Test (accuracy) score:\\', score)\\n        \\n        if counter == 1:\\n            \\n            list1_params.append(grid.best_params_)\\n\\n            list1_grid.append(grid)\\n\\n            list1_pred.append(y_test_pred)\\n            \\n            list1_score.append(score)\\n            \\n            list1_cm.append(cm)\\n            \\n            list1_f1.append(f1)\\n            \\n            list1_metrics.append(class_metrics)\\n\\n        if counter == 2:\\n            list2_params.append(grid.best_params_)\\n\\n            list2_grid.append(grid)\\n            \\n            list2_pred.append(y_test_pred)\\n            \\n            list2_score.append(score)\\n            \\n            list2_cm.append(cm)\\n            \\n            list2_f1.append(f1)\\n            \\n            list2_metrics.append(class_metrics)\\n            \\n        if counter == 3:\\n            list3_params.append(grid.best_params_)\\n\\n            list3_grid.append(grid)\\n\\n            list3_pred.append(y_test_pred)\\n\\n            list3_score.append(score)\\n            \\n            list3_cm.append(cm)\\n            \\n            list3_f1.append(f1)\\n            \\n            list3_metrics.append(class_metrics)\\n            \\n        if counter == 4:\\n            list4_params.append(grid.best_params_)\\n\\n            list4_grid.append(grid)\\n\\n            list4_pred.append(y_test_pred)\\n\\n            list4_score.append(score)\\n            \\n            list4_cm.append(cm)\\n            \\n            list4_f1.append(f1)\\n            \\n            list4_metrics.append(class_metrics)\\n            \\n        if counter == 5:\\n            list5_params.append(grid.best_params_)\\n\\n            list5_grid.append(grid)\\n\\n            list5_pred.append(y_test_pred)\\n\\n            list5_score.append(score)\\n            \\n            list5_cm.append(cm)\\n            \\n            list5_f1.append(f1)\\n            \\n            list5_metrics.append(class_metrics)\\n            \\n        print()    \\n    \\n    \\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "%%time\n",
    "\n",
    "## Perform 60-20-20 Split\n",
    "# splitter for subsampled data\n",
    "stratGroupKFold2 = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "# splitter for other\n",
    "stratGroupKFold3 = StratifiedGroupKFold(n_splits=4)\n",
    "\n",
    "# label encoder for XGBoost\n",
    "le = LabelEncoder()\n",
    "y_subsample2 = le.fit_transform(y_subsample2)\n",
    "\n",
    "# Initialize lists\n",
    "nr_states = [0,1,2] # ,1,2\n",
    "test_scores = []\n",
    "final_models = []\n",
    "best_params = []\n",
    "test_scores = []\n",
    "counter = 0\n",
    "\n",
    "# num of lists should equal number of test sets that the StratifiedGroupKFold will generate\n",
    "# each list should contain entries with the same number of random state\n",
    "    \n",
    "list1_params = []\n",
    "list1_grid = []\n",
    "list1_pred = []\n",
    "list1_score = []\n",
    "list1_means = []\n",
    "list1_cm = []\n",
    "list1_stds = []\n",
    "list1_metrics = []\n",
    "\n",
    "list1_f1 = []\n",
    "\n",
    "list2_params = []\n",
    "list2_grid = []\n",
    "list2_pred = []\n",
    "list2_score = []\n",
    "list2_means = []\n",
    "list2_stds = []\n",
    "list2_cm = []\n",
    "list2_ytest = []\n",
    "list2_metrics = []\n",
    "list2_f1 = []\n",
    "\n",
    "list3_params = []\n",
    "list3_grid = []\n",
    "list3_pred = []\n",
    "list3_score = []\n",
    "list3_means = []\n",
    "list3_stds = []\n",
    "list3_cm = []\n",
    "list3_metrics = []\n",
    "list3_f1 = []\n",
    "\n",
    "list4_params = []\n",
    "list4_grid = []\n",
    "list4_pred = []\n",
    "list4_score = []\n",
    "list4_means = []\n",
    "list4_stds = []\n",
    "list4_cm = []\n",
    "list4_metrics = []\n",
    "list4_f1 = []\n",
    "\n",
    "list5_params = []\n",
    "list5_grid = []\n",
    "list5_pred = []\n",
    "list5_score = []\n",
    "list5_means = []\n",
    "list5_stds = []\n",
    "list5_cm = []\n",
    "list5_metrics = []\n",
    "list5_f1 = []\n",
    "\n",
    "for i_other2,i_test2 in stratGroupKFold2.split(X_subsample2.values, y_subsample2, groups_subsample2.values):\n",
    "    \n",
    "    counter = counter + 1\n",
    "    \n",
    "    X_other2, y_other2, groups_other2 = X_subsample2.values[i_other2], y_subsample2[i_other2], groups_subsample2.values[i_other2]\n",
    "    X_test2, y_test2, groups_test2 = X_subsample2.values[i_test2], y_subsample2[i_test2], groups_subsample2.values[i_test2]\n",
    "\n",
    "    # Reshape the data\n",
    "    \n",
    "    X_other2 = pd.DataFrame(X_other2)\n",
    "    X_other2.columns = X_subsample2.columns\n",
    "    \n",
    "    X_test2 = pd.DataFrame(X_test2)\n",
    "    X_test2.columns = X_subsample2.columns\n",
    "\n",
    "    y_other2 = pd.DataFrame(y_other2)\n",
    "    y_other2.columns = y_subsample2_columns\n",
    "    \n",
    "\n",
    "    groups_other2 = pd.DataFrame(groups_other2)\n",
    "    groups_other2.columns = groups_subsample2.columns\n",
    "\n",
    "    y_other2 = np.reshape(np.array(y_other2), (1, -1)).ravel()\n",
    "    \n",
    "    \n",
    "    y_test2 = np.reshape(np.array(y_test2), (1, -1)).ravel()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'Test Set #{counter}')\n",
    "\n",
    "    print(\"    Test Set Size:\", len(y_test2))\n",
    "    \n",
    "    print(\"    X_test Shape:\", X_test2.shape)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    for i in range(len(nr_states)):\n",
    "\n",
    "        print(\"         Random State:\", i)\n",
    "        print()\n",
    "\n",
    "        # Perform n-Fold CV\n",
    "        cv = stratGroupKFold3.split(X_other2, y_other2, groups_other2)\n",
    "\n",
    "\n",
    "        # Initialize XGBoost Classifier\n",
    "        clf = xgb.XGBClassifier(num_class=3,\n",
    "                                eval_metric = \"mlogloss\",\n",
    "                                objective = \"multi:softprob\",\n",
    "                                random_state = i, \n",
    "                                use_label_encoder = False)\n",
    "\n",
    "        pipe = make_pipeline(preprocessor,clf)\n",
    "\n",
    "        grid = GridSearchCV(pipe, \n",
    "                            param_grid=param_grid,\n",
    "                            scoring = \"f1_macro\", #‘f1_macro’ #scorer #accuracy\n",
    "                            cv=cv, \n",
    "                            return_train_score = True, \n",
    "                            n_jobs=1, \n",
    "                            verbose=10)\n",
    "        \n",
    "        # Compute sample weights\n",
    "        weights = compute_sample_weight(class_weight='balanced', y = y_other2)\n",
    "        \n",
    "        print(f'Feature weights: {np.unique(weights)}')\n",
    "\n",
    "        grid_result = grid.fit(X_other2, y_other2, groups = groups_other2,\n",
    "                              xgbclassifier__sample_weight = weights) #xgbclassifier__early_stopping_rounds=50\n",
    "        \n",
    "        print()\n",
    "        print('best model parameters:', grid.best_params_)\n",
    "\n",
    "        print()\n",
    "\n",
    "        print('validation score:',grid.best_score_)\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        \n",
    "        y_test_pred = grid.predict(X_test2)\n",
    "        score = accuracy_score(y_test2,y_test_pred)\n",
    "        cm = confusion_matrix(y_test2, y_test_pred)\n",
    "        f1 = f1_score(y_test2, y_test_pred)\n",
    "        class_metrics = metrics.classification_report(y_test2, y_test_pred, digits=3)\n",
    "        \n",
    "        print('Test (accuracy) score:', score)\n",
    "        \n",
    "        if counter == 1:\n",
    "            \n",
    "            list1_params.append(grid.best_params_)\n",
    "\n",
    "            list1_grid.append(grid)\n",
    "\n",
    "            list1_pred.append(y_test_pred)\n",
    "            \n",
    "            list1_score.append(score)\n",
    "            \n",
    "            list1_cm.append(cm)\n",
    "            \n",
    "            list1_f1.append(f1)\n",
    "            \n",
    "            list1_metrics.append(class_metrics)\n",
    "\n",
    "        if counter == 2:\n",
    "            list2_params.append(grid.best_params_)\n",
    "\n",
    "            list2_grid.append(grid)\n",
    "            \n",
    "            list2_pred.append(y_test_pred)\n",
    "            \n",
    "            list2_score.append(score)\n",
    "            \n",
    "            list2_cm.append(cm)\n",
    "            \n",
    "            list2_f1.append(f1)\n",
    "            \n",
    "            list2_metrics.append(class_metrics)\n",
    "            \n",
    "        if counter == 3:\n",
    "            list3_params.append(grid.best_params_)\n",
    "\n",
    "            list3_grid.append(grid)\n",
    "\n",
    "            list3_pred.append(y_test_pred)\n",
    "\n",
    "            list3_score.append(score)\n",
    "            \n",
    "            list3_cm.append(cm)\n",
    "            \n",
    "            list3_f1.append(f1)\n",
    "            \n",
    "            list3_metrics.append(class_metrics)\n",
    "            \n",
    "        if counter == 4:\n",
    "            list4_params.append(grid.best_params_)\n",
    "\n",
    "            list4_grid.append(grid)\n",
    "\n",
    "            list4_pred.append(y_test_pred)\n",
    "\n",
    "            list4_score.append(score)\n",
    "            \n",
    "            list4_cm.append(cm)\n",
    "            \n",
    "            list4_f1.append(f1)\n",
    "            \n",
    "            list4_metrics.append(class_metrics)\n",
    "            \n",
    "        if counter == 5:\n",
    "            list5_params.append(grid.best_params_)\n",
    "\n",
    "            list5_grid.append(grid)\n",
    "\n",
    "            list5_pred.append(y_test_pred)\n",
    "\n",
    "            list5_score.append(score)\n",
    "            \n",
    "            list5_cm.append(cm)\n",
    "            \n",
    "            list5_f1.append(f1)\n",
    "            \n",
    "            list5_metrics.append(class_metrics)\n",
    "            \n",
    "        print()    \n",
    "    \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list3_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ValueError: Specifying the columns using strings is only supported for pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix after performing XGBoost with gridsearchCV and multiple random states, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35 min for paramgrid1 with 60-20-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save XGBoost Results to a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
